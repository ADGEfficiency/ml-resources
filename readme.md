A refactor of my personal machine learning resources.  If you like this check out [rl-resources](https://github.com/ADGEfficiency/rl-resources) and [programming resources](https://github.com/ADGEfficiency/programming-resources).

## If you are starting out with machine learning

For neural networks - [Deep Learning - Ian Goodfellow, Yoshua Bengio and Aaron Courville](https://www.deeplearningbook.org/) - read chapters 1-3, 5-6, 111-12

For everything else (linear models, random forests etc) 

- [Elements of Statistical Learning - Trevor Hastie, Robert Tibshirani and Jerome Friedman](https://web.stanford.edu/~hastie/Papers/ESLII.pdf) - read chapters 1-4, 7-8 and 9
- [Pattern Recognition and Machine Learning - Christopher M. Bishop](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)

There is also [An Introduction to Statistical Learning - James et. al](http://faculty.marshall.usc.edu/gareth-james/ISL/), which covers the same topics as Elements of Statistical Learning, but concentrates on applications & less on math.

[floodsung/Deep-Learning-Papers-Reading-Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap) - answers the question 'Which paper should I start reading from?'

## Math

Deep Learning:
- 2.1, 2.2, 2.3, 2.5
- 3.1  3.8

## Podcasts

[Lex Fridman - AI Podcast](https://www.youtube.com/playlist?list=PLrAXtmErZgOdP_8GztsuKi9nrraNbKKp4)

- [Juergen Schmidhuber](https://www.youtube.com/watch?v=3FIo6evmweo&t=0s)
- [Pieter Abbeel](https://www.youtube.com/watch?v=l-mYLq6eZPY&t=0s)
- [Oriol Vinyals](https://www.youtube.com/watch?v=Kedt2or9xlo)
- [Ian Goodfellow](https://www.youtube.com/watch?v=Z6rxFNMGdn0)
- [Guido van Rossum](https://www.youtube.com/watch?v=ghwaIiE3Nd8)
- [George Hotz](https://www.youtube.com/watch?v=iwcYp-XT7UI)
- [Yann LeCun](https://www.youtube.com/watch?v=SGSOCuByo24)
- [Jeremy Howard - fastai](https://www.youtube.com/watch?v=J6XcP4JOHmk)
- [Greg Brockman - OpenAI](https://www.youtube.com/watch?v=bIrEM2FbOLU)
- [Yoshua Bengio](https://www.youtube.com/watch?v=azOmzumh0vQ)
- [François Chollet - Keras](https://www.youtube.com/watch?v=Bo8MY4JpiXE)
- [Grant Sanderson - 3Blue1Brown](https://www.youtube.com/watch?v=U_lKUK2MCsg)

[Talking Machines](http://www.thetalkingmachines.com/)
- [The Deep End of Deep Learning](http://www.thetalkingmachines.com/episodes/deep-end-deep-learning?context_entity_type=node&context_entity_id=29216)
- 
This Week in AI
- [Are We Being Honest About How Difficult AI Really Is? with David Ferrucc](https://twimlai.com/twiml-talk-268-are-we-being-honest-about-how-difficult-ai-really-is-with-david-ferrucci/)

## [The Bitter Lesson - Rich Sutton - 2019](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)

> One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning. 

> The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries.

## Ecosystem

[Papers With Code](https://paperswithcode.com/) - a free and open resource with Machine Learning papers, code and evaluation tables
- [slack](https://join.slack.com/t/paperswithcode/shared_invite/enQtNzE2NDQyMTAxNDEzLTMxNmY2NTc4ZWYzZGJhZGRmZGFkNzVhNTI1OTZhYzFlZWZiZDQ0M2M5ZTkyYzNhZmZhZmRlMjkxNGQxZGEwZjA)
- [state of the art](https://paperswithcode.com/sota)

[Distill](https://distill.pub/) - Machine Learning Research Should Be Clear, Dynamic and Vivid. Distill Is Here to Help.

[r/MachineLearning](https://www.reddit.com/r/MachineLearning/) - the Machine Learning reddit
- [slack](https://join.slack.com/t/rml-talk/shared_invite/enQtNjkyMzI3NjA2NTY2LWY0ZmRjZjNhYjI5NzYwM2Y0YzZhZWNiODQ3ZGFjYmI2NTU3YjE1ZDU5MzM2ZTQ4ZGJmOTFmNWVkMzFiMzVhYjg)

## Talks

[Demis Hassabis (CEO DeepMind) &#8211; Artificial Intelligence and the Future](https://www.youtube.com/watch?v=i3lEG6aRGm8)

[Artificial Intelligence is the New Electricity - Andrew Ng](https://www.youtube.com/watch?v=zWQOJ001PDs)

[Nuts and Bolts of Applying Deep Learning - Andrew Ng](https://www.youtube.com/watch?v=F1ka6a13S9I)

## Blogs

[Berkeley Artifical Intelligence Research - BAIR](https://bair.berkeley.edu/blog/)
- [When Recurrent Models Don't Need to be Recurrent](https://bair.berkeley.edu/blog/2018/08/06/recurrent/)

[lossfunctions](https://lossfunctions.tumblr.com/)

[colah's blog](https://colah.github.io/)
- [Visual Information Theory](https://colah.github.io/posts/2015-09-Visual-Information/)
- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

[Berkeley Artifical Intelligence Research (BAIR)](https://bair.berkeley.edu/blog/)

Andrej Karpathy - [gitpages blog](http://karpathy.github.io/) - [medium](https://medium.com/@karpathy)
- [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)
- [Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35)
- [Yes you should understand backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)

[A Recipe for Training Neural Networks - Andrej Karpathy](https://karpathy.github.io/2019/04/25/recipe/)

## Non-technical overviews

[How computers got shockingly good at recognizing images - Ars Technica](https://arstechnica.com/science/2018/12/how-computers-got-shockingly-good-at-recognizing-images/)

[The basics of modern AI—how does it work and will it destroy society this year? - Ars Technica](https://arstechnica.com/features/2019/04/from-ml-to-gan-to-hal-a-peak-behind-the-modern-artificial-intelligence-curtain/)

[Dairy farming, solar panels, and diagnosing Parkinson's disease: what can you do with deep learning? - fast.ai](https://www.fast.ai/2019/02/21/dl-projects/)

[The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World (2015 book) - Pedro Domingos](https://en.wikipedia.org/wiki/The_Master_Algorithm)

[Algorithms to Live By: The Computer Science of Human Decisions - Christian & Griffiths](https://www.goodreads.com/book/show/25666050-algorithms-to-live-by)

[Superintelligence: Paths, Dangers, Strategies (2014 book) - Nick Bostrom](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies)

[How Not to Be Wrong: The Power of Mathematical Thinking - Jordan Ellenberg](https://en.wikipedia.org/wiki/How_Not_to_Be_Wrong)

[Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/)

## Criticism

[2018 - The rise of 'pseudo-AI': how tech firms quietly use humans to do bots' work](https://www.theguardian.com/technology/2018/jul/06/artificial-intelligence-ai-humans-bots-tech-companies)

[2018 - Artificial intelligence: winter is coming - Financial Times](https://www.ft.com/content/47111fce-d0a4-11e8-9a3c-5d5eac8f1ab4)

[2018 - What worries me about AI – François Chollet](https://medium.com/@francois.chollet/what-worries-me-about-ai-ed9df072b704)

[2019 - Our Entire AI Revolution Is Built On A Correlation House Of Cards - Forbes](https://www.forbes.com/sites/kalevleetaru/2019/04/20/our-entire-ai-revolution-is-built-on-a-correlation-house-of-cards/#22c051a54969)

[2019 - Machine learning systems are stuck in a rut](https://blog.acolyer.org/2019/06/28/machine-learning-systems-are-stuck-in-a-rut/)

[2019 - DeepMind's losses and the future of artificial intelligence - WIRED](https://www.wired.com/story/deepminds-losses-future-artificial-intelligence/)

## Domain specific

[The financial world wants to open AI's boxes &#8211; MIT Technology Review](https://www.technologyreview.com/s/604122/the-financial-world-wants-to-open-ais-black-boxes/)

## Datasets

[UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)

## Misc

[Paperclip maximizer](https://wiki.lesswrong.com/wiki/Paperclip_maximizer)

## Textbooks

[Introduction to High-Performance Scientific Computing - Victor Eijkhout](http://pages.tacc.utexas.edu/~eijkhout/istc/html/index.html)

[Think Stats 2nd Edition](https://greenteapress.com/wp/think-stats-2e/).

## Courses

Bay Area Deep Learning School

[Day One](https://www.youtube.com/watch?v=eyovmAtoUx0)

- [Deep Learning - Hugo Larochelle](https://youtu.be/eyovmAtoUx0?list=WL&t=585)
- [Vision - Andrej Karpathy](https://youtu.be/eyovmAtoUx0?list=WL&t=5266)
- [NLP - Richard Socher](https://youtu.be/eyovmAtoUx0?t=14036)
- [Unsupervised - Ruslan Salakhutdinov](https://youtu.be/eyovmAtoUx0?list=WL&t=25874)

[Day Two](https://www.youtube.com/watch?v=9dXiAecyJrY)

- [Reinforcement Learning - John Schulman](https://youtu.be/9dXiAecyJrY?t=361)
- [Theano - Pascal Lamblin](https://youtu.be/9dXiAecyJrY?t=6702)
- [Speech recognition - Adam Coates](https://youtu.be/9dXiAecyJrY?t=13878)
- [Torch - Alex Wiltschko](https://youtu.be/9dXiAecyJrY?t=20966)
- [Sequences - Quoc Lee](https://youtu.be/9dXiAecyJrY?t=25463)
- [Foundations & Challenges - Yoshua Bengio](https://youtu.be/9dXiAecyJrY?t=30704)

Full Stack Deep Learning - [March 2019 videos](https://fullstackdeeplearning.com/march2019)

- [Lecture 3: Jeremy Howard](https://www.youtube.com/watch?v=hZd3X_nGdew)

- [Lecture 8: Troubleshooting Deep Neural Networks - Josh Tobin](https://www.youtube.com/watch?v=GwGTwPcG0YM)
- [Lecture 9: Testing and Deployment - Sergey Karayev](https://www.youtube.com/watch?v=nu7h1zdKPd0)



