[When ChatGPT summarises, it actually does nothing of the kind](https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/) - [Hacker News](https://news.ycombinator.com/item?id=41027658)

Summarization versus shorten.  Summarization requires understanding.

ChatGPT doesn't actually summarize texts, but instead shortens them without understanding the material.

Can miss key points.

Can oversimplify or hallucinate.

---

There are several strategies that allow good results with just a few iterations - for example, including a list of key questions to be answered

The actual ‘intelligence’ (what to include, and what is actually said) has to come from the user, not the system.

[Against Predictive Optimization](https://predictive-optimization.cs.princeton.edu/)

Predictive optimization to refer to automated decision-making systems where machine learning is used to make predictions about some future outcome pertaining to individuals, and those predictions are used to make decisions about them. 

## Seven flaws of predictive optimization

### Good predictions may not lead to good decisions

### It's hard to measure what we truly care about 

### The training data rarely matches the deployment setting 

### Social outcomes aren’t accurately predictable, with or without machine learning 

### Disparate performance between groups can’t be fixed by algorithmic interventions 

However, a system that is fair in a statistical sense may nonetheless perpetuate, reify, or even amplify long-standing cycles of inequality. 

### Providing adequate contestability undercuts putative efficiency benefits 

In many cases, the decisions were based on incorrect data, but the decision subjects had no recourse.

### Predictive optimization doesn't account for strategic behavior 

Predictive optimization can create unintended incentives for decision subjects to game the system.

[What is wrong with convolutional neural nets? - Geoffrey Hinton - Fields Institute, 2017](https://www.youtube.com/watch?v=Mqt8fs6ZbHk)

[This AI startup claims to automate app making but actually just uses humans](https://www.theverge.com/2019/8/14/20805676/engineer-ai-artificial-intelligence-startup-app-development-outsourcing-humans)

[The rise of 'pseudo-AI': how tech firms quietly use humans to do bots' work](https://www.theguardian.com/technology/2018/jul/06/artificial-intelligence-ai-humans-bots-tech-companies)

[An understanding of AI’s limitations is starting to sink in](https://www.economist.com/technology-quarterly/2020/06/11/an-understanding-of-ais-limitations-is-starting-to-sink-in)

[How to recognize AI snake oil](https://www.cs.princeton.edu/~arvindn/talks/MIT-STS-AI-snakeoil.pdf)
